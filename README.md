
# AutoJudge

**AI-Powered Programming Problem Difficulty Prediction**

AutoJudge is a machine learning system that automatically predicts the **difficulty class** (Easy / Medium / Hard) and a **numerical difficulty score** for programming problems using only their **textual descriptions**.

The project is inspired by online competitive programming platforms (Codeforces, CodeChef, Kattis), where problem difficulty is typically assigned manually. AutoJudge aims to **automate this process** using Natural Language Processing (NLP) and classical machine learning models.

---

## ğŸš€ Features

* Predicts **problem difficulty class** (Easy / Medium / Hard)
* Predicts a **numerical difficulty score**
* Uses **only text input** (no code or metadata)
* Implements **baseline and improved models**
* Clean and interactive **Flask web interface**
* No deep learning â€” fully interpretable ML models

---

## ğŸ“‚ Project Structure

```
AutoJudge/
â”‚
â”œâ”€â”€ app.py                      # Flask application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ problems.csv            # Preprocessed dataset
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ jsonl_to_csv.py          # Dataset conversion
â”‚   â”œâ”€â”€ preprocess.py            # Text cleaning & preprocessing
â”‚   â”œâ”€â”€ features.py              # TF-IDF feature extraction
â”‚   â”œâ”€â”€ train_classifier.py      # Baseline classifier (Logistic Regression)
â”‚   â”œâ”€â”€ train_classifier_svm.py  # Improved classifier (SVM)
â”‚   â”œâ”€â”€ train_regressor.py       # Baseline regressor (Ridge)
â”‚   â”œâ”€â”€ train_regressor_rf.py    # Improved regressor (Random Forest)
â”‚   â””â”€â”€ predict.py               # Prediction pipeline
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ classifier.pkl
â”‚   â”œâ”€â”€ classifier_svm.pkl
â”‚   â”œâ”€â”€ vectorizer.pkl
â”‚   â”œâ”€â”€ vectorizer_svm.pkl
â”‚   â”œâ”€â”€ regressor_ridge.pkl
â”‚   â”œâ”€â”€ regressor_rf.pkl
â”‚   â”œâ”€â”€ vectorizer_ridge.pkl
â”‚   â””â”€â”€ vectorizer_rf.pkl
â”‚
â””â”€â”€ templates/
    â””â”€â”€ index.html               # Web UI
```

---

## ğŸ“Š Dataset

The dataset is sourced from:

**TaskComplexityEval-24**
[https://github.com/AREEG94FAHAD/TaskComplexityEval-24](https://github.com/AREEG94FAHAD/TaskComplexityEval-24)

Each sample contains:

* `title`
* `description`
* `input_description`
* `output_description`
* `problem_class` (easy / medium / hard)
* `problem_score` (numerical)

The raw JSONL file is converted into CSV using `jsonl_to_csv.py`, followed by text preprocessing and feature extraction.

---

## âš™ï¸ Data Preprocessing

* Combined all text fields into a single input
* Removed missing values
* Normalized and cleaned text
* Generated TF-IDF features with unigrams and bigrams

---

## ğŸ§  Models Used

### ğŸ”¹ Classification (Difficulty Class)

**Baseline Model**

* Logistic Regression
* Accuracy â‰ˆ **0.496**

**Improved Model**

* Support Vector Machine (LinearSVC)
* Accuracy â‰ˆ **0.503**
* Uses class balancing and tuned regularization

---

### ğŸ”¹ Regression (Difficulty Score)

**Baseline Model**

* Ridge Regression
* MAE â‰ˆ **1.72**
* RMSE â‰ˆ **2.06**

**Improved Model**

* Random Forest Regressor
* MAE â‰ˆ **1.71**
* RMSE â‰ˆ **2.05**

Although numerical improvements are modest, Random Forest captures non-linear relationships better than linear regression.

---

## ğŸ“ˆ Evaluation Metrics

* **Classification**

  * Accuracy
  * Confusion Matrix
  * Precision / Recall / F1-Score

* **Regression**

  * Mean Absolute Error (MAE)
  * Root Mean Squared Error (RMSE)

---

## ğŸŒ Web Interface

The project includes a Flask-based web application that allows users to:

1. Enter:

   * Problem Title
   * Problem Description
   * Input Description
   * Output Description
2. Click **Predict Difficulty**
3. View:

   * Predicted Difficulty Class (color-coded)
   * Predicted Difficulty Score

The UI is clean, responsive, and designed for easy demonstration.

---
## ğŸ“„ Project Report
The detailed project report explaining the problem statement, dataset, preprocessing, feature engineering, models, evaluation metrics, and web interface is available here:

ğŸ‘‰ [Project Report (PDF)](https://drive.google.com/file/d/1zeX8r4hvQt6gNe2tsB2ktc5Z5dNY0guq/view?usp=sharing)

---

## ğŸ¥ Demo Video
A demo video showing the project overview, model approach, and working web interface is available here:

ğŸ‘‰ [Demo Video Link](https://drive.google.com/file/d/1a7yupkj6ZiORg8bL0AXlOAOt_zfjL7AR/view?usp=sharing)


## â–¶ï¸ How to Run

### 1ï¸âƒ£ Clone the repository  
```bash
git clone https://github.com/gunimishra273/AutoJudge.git
cd AutoJudge
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the Flask app

```bash
python app.py
```

### 4ï¸âƒ£ Open in browser

```
http://127.0.0.1:5000
```

---

## ğŸ§ª Training the Models (Optional)

To retrain models from scratch:

```bash
python src/train_classifier.py
python src/train_classifier_svm.py
python src/train_regressor.py
python src/train_regressor_rf.py
```

Trained models are saved automatically in the `models/` directory.

---

## ğŸ”® Future Improvements

* Use transformer-based embeddings (BERT)
* Add dataset balancing techniques
* Improve regression accuracy with ensemble tuning
* Support multi-language problem descriptions

---

## ğŸ§¾ Conclusion

AutoJudge demonstrates that **problem difficulty can be reasonably predicted using only textual information**.
The project showcases a complete ML pipeline â€” from preprocessing and modeling to deployment and UI â€” making it suitable for academic evaluation and live demos.

---

## ğŸ‘©â€ğŸ’» Author

**Guni Mishra**

---
